# -*- coding: utf-8 -*-
"""Textual Analysis Model : Finance

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xkDtRbLVydnaHL0BY7efrsJIo1QVGSIT

#### DATA INGESTION
- This section involves collecting, importing, and preparing data from kaggle for analysis and processing.
- It is crucial for enabling accurate insights and decision-making based on the ingested data.
"""

# Importing Necessary Libraries
import os
import pandas as pd
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader, TensorDataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from transformers import Trainer, TrainingArguments
from sklearn.metrics import classification_report, accuracy_score
from sklearn.model_selection import train_test_split

# Uploading the Kaggle API Key
from google.colab import files

# Upload your kaggle.json file
uploaded = files.upload()

# Move the kaggle.json to the correct directory
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json  # Set permissions for the API key

# Load the Dataset
!pip install kaggle  # Install Kaggle API
!kaggle datasets download -d sbhatti/financial-sentiment-analysis  # Download the dataset

# Unzipping the downloaded dataset
import zipfile
import os

with zipfile.ZipFile("financial-sentiment-analysis.zip", "r") as zip_ref:
    zip_ref.extractall(".")  # Extract files to the current directory

# List the contents of the current directory to find the CSV file
extracted_files = os.listdir(".")
print("Extracted files:", extracted_files)

# Loading the dataset into a DataFrame
data = pd.read_csv("data.csv")
print(data.head())  # Display the first few rows of the dataset

"""#### DATA PREPROCESSING
- This involves cleaning and preparing the dataset for model training.
"""

# Checking for missing values
print(data.isnull().sum())

# Encoding the target labels
label_mapping = {'positive': 2, 'neutral': 1, 'negative': 0}
data['label'] = data['Sentiment'].map(label_mapping)

# Splitting the dataset into training and testing sets
train_texts, test_texts, train_labels, test_labels = train_test_split(
    data['Sentence'].tolist(),
    data['label'].tolist(),
    test_size=0.2,
    random_state=42
)

print(f"Training samples: {len(train_texts)}, Testing samples: {len(test_texts)}")

"""#### TOKENIZATION
- This involves tokenizing the text data for the FinBERT model.
"""

# Tokenization

tokenizer = AutoTokenizer.from_pretrained("yiyanghkust/finbert-tone")  # Load the FinBERT tokenizer

# Tokenizing the training and testing data
train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)
test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)

"""#### DATA PREPARATION
- This involves preparing the data for PyTorch by converting encodings to tensors.
"""

# Preparing the train and test datasets
train_encodings_tensor = {key: torch.tensor(val) for key, val in train_encodings.items()}
train_labels_tensor = torch.tensor(train_labels)

test_encodings_tensor = {key: torch.tensor(val) for key, val in test_encodings.items()}
test_labels_tensor = torch.tensor(test_labels)

# Creating TensorDataset for PyTorch
train_dataset = TensorDataset(train_encodings_tensor['input_ids'],
                               train_encodings_tensor['attention_mask'],
                               train_labels_tensor)

test_dataset = TensorDataset(test_encodings_tensor['input_ids'],
                              test_encodings_tensor['attention_mask'],
                              test_labels_tensor)

# Creating DataLoader
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64)

"""#### MODEL SELECTION AND INITIALIZATION
- This involves selecting and initializing the FinBERT model for fine-tuning.
"""

# Model Selection and Initialization
model = AutoModelForSequenceClassification.from_pretrained("yiyanghkust/finbert-tone", num_labels=3)

"""#### MODEL TRAINING
- The model training process converts input encodings and labels into tensor datasets and uses a Trainer object to iteratively learn from training data while evaluating performance.
"""

# Convert encodings and labels to tensors, then create a list of dictionaries
train_dataset = [
    {'input_ids': torch.tensor(input_id), 'attention_mask': torch.tensor(attention_mask), 'labels': torch.tensor(label)}
    for input_id, attention_mask, label in zip(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)
]

test_dataset = [
    {'input_ids': torch.tensor(input_id), 'attention_mask': torch.tensor(attention_mask), 'labels': torch.tensor(label)}
    for input_id, attention_mask, label in zip(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)
]

# Training setup
training_args = TrainingArguments(
    output_dir='./results',           # Directory for model checkpoints
    num_train_epochs=10,              # Number of training epochs
    per_device_train_batch_size=16,   # Batch size for training
    per_device_eval_batch_size=64,    # Batch size for evaluation
    warmup_steps=500,                 # Warmup steps for learning rate scheduling
    weight_decay=0.01,                # Weight decay to reduce overfitting
    logging_dir='./logs',             # Directory for logs
    logging_steps=10,                 # Log every 10 steps
    eval_strategy="epoch",             # Evaluate at the end of each epoch
    save_strategy="epoch",            # Save the model at the end of every epoch
    save_total_limit=2,               # Keep only the 2 most recent checkpoints
    resume_from_checkpoint=True       # Allows resuming from a checkpoint
)

# Using the Trainer for training
trainer = Trainer(
    model=model,
    args=training_args,               # Training arguments
    train_dataset=train_dataset,      # Training dataset as a list of dictionaries
    eval_dataset=test_dataset         # Evaluation dataset as a list of dictionaries
)

# Train the model
trainer.train()

"""#### MODEL EVALUATION
- This involves evaluating the model on the test dataset and generating a classification report.
"""

# Predicting on the test dataset
predictions, labels, _ = trainer.predict(test_dataset)

# Get the predicted labels
predicted_labels = np.argmax(predictions, axis=1)

# Generating the classification report
print(classification_report(test_labels, predicted_labels, target_names=['Negative', 'Neutral', 'Positive']))
print(f"Accuracy: {accuracy_score(test_labels, predicted_labels):.4f}")

model.save_pretrained("/content/finetuned_model")

import os

# Define the path to the saved model
model_directory = "/content/finetuned_model"

# Calculate the size of the model directory
total_size = 0
for dirpath, dirnames, filenames in os.walk(model_directory):
    for f in filenames:
        fp = os.path.join(dirpath, f)
        total_size += os.path.getsize(fp)

# Convert to megabytes (MB)
total_size_mb = total_size / (1024 * 1024)

print(f"Model size after fine-tuning: {total_size_mb:.2f} MB")

"""#### RESULTS AND CONCLUSIONS

- This section involves summarizing the results and discussing the implications.
"""

# Results and observations
print("Results:")
print(f"Model achieved an accuracy of {accuracy_score(test_labels, predicted_labels):.2%} on the test set.")

"""###### CONCLUSION
- The FinBERT model was fine-tuned on a Financial Sentiment Analysis dataset and performed well, with an accuracy of 77.50%. It was especially good at identifying Neutral and Positive sentiments, scoring 0.82 and 0.87 in these categories. This makes the model useful for tasks like automated trading and sentiment analysis, which are important for understanding market moods.
However, the model didn't do as well with Negative sentiments, scoring 0.38. This means it has trouble recognizing negative opinions, which could be important for spotting risks or market declines. Improving how the model handles negative sentiment would be helpful for better predicting risks in finance.

- Key Points: The model is strong at recognizing Neutral and Positive sentiments, which are common in financial texts. It struggles with Negative sentiment, which may be due to having fewer examples (175 samples), making it harder for the model to recognize.

- Future work could involve exploring hyperparameter tuning, experimenting with different models, or incorporating additional datasets to enhance performance further.
"""